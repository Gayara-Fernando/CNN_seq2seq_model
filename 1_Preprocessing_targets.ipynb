{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3577020d-7037-4359-8f04-ab181f5a0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need the features extracted for the final 7 images (sub-images) in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8b6e7b-9ba5-48b1-8347-882017828755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 18:31:49.414620: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-14 18:31:49.450805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-14 18:31:49.450828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-14 18:31:49.451817: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-14 18:31:49.458006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0652ccb-780b-4808-a020-d9abd5242a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 18:31:51.447803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# import the trained model\n",
    "\n",
    "model = tf.keras.models.load_model(\"../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e39505-3148-4204-ae56-c1ef9fc63bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383340aa-1c83-45c9-9b98-6d99f33a2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extractor model\n",
    "\n",
    "# feature extractor input\n",
    "feat_ext_input = model.input\n",
    "\n",
    "# feature extractor output - do this at the ReLu activation layer - as this will give the same features as the dropout layer (It does not matter if it is the dropout or the activation layer, the extracted features will be the same)\n",
    "feat_ext_output = model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5827588a-d52f-43ac-967d-8447f61f2688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47fbeaed-4503-4008-b79b-29bace024a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now let's worry about the data. We only need the features extracted for the last 7 images in teh sequence. Let's get these here? Also note that we do not have anything to do with the density maps for now, for the stage 1 implementaiton at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d492cd3-9c37-4aec-a8fa-2e9b8d84f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions will help create all the required matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a347fde-0d86-4a6a-9914-2111aa26e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chose_xml_and_jpeg(file_location):\n",
    "    # list all files in location\n",
    "    list_of_all_files = os.listdir(file_location)\n",
    "    # sort files\n",
    "    list_of_all_files.sort()\n",
    "    # separate xml and jpeg files\n",
    "    all_xml_files = [file for file in list_of_all_files if file.split('.')[-1] == 'xml']\n",
    "    all_xml_files.sort()\n",
    "    all_jpeg_files = [file for file in list_of_all_files if file not in all_xml_files]\n",
    "    all_jpeg_files.sort()\n",
    "    # get the final 7 image files\n",
    "    chosen_jpeg_files = all_jpeg_files[-7:]\n",
    "    \n",
    "    return chosen_jpeg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10d5466-d982-4fc0-b10f-df13467531b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sub_windows(folder_path, file, stride = 30, kernel_size = 30):\n",
    "    # joined image path\n",
    "    joined_im_path = os.path.join(folder_path, file)\n",
    "    # read the image\n",
    "    loaded_im_file = plt.imread(joined_im_path)\n",
    "    # create subwindows and get prediction\n",
    "    img_height = loaded_im_file.shape[0]\n",
    "    img_width = loaded_im_file.shape[1]\n",
    "\n",
    "    # catch all subwindows here\n",
    "    all_subwindows = []\n",
    "    # you can also keep track the subwindows here if required - but let's not worry about that for now\n",
    "    for i in  range(0, img_height, stride):\n",
    "        for j in range(0, img_width, stride):\n",
    "            sub_window = loaded_im_file[i: i + kernel_size, j : j + kernel_size,:]\n",
    "            # resize the subwindow - for 300*300\n",
    "            sub_window = resize(sub_window, (kernel_size, kernel_size,3))\n",
    "            # append these to the list\n",
    "            all_subwindows.append(sub_window)\n",
    "            \n",
    "    return all_subwindows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff3270e-9784-4fa1-9088-b3560abfc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name, file_path):\n",
    "    # get the subwindows\n",
    "    subwindows = create_sub_windows(file_path, file_name, 30, 30)\n",
    "    # stack the subwindows\n",
    "    stacked_subwindows = np.stack(subwindows, axis = 0)\n",
    "    # print the shape of this\n",
    "    print(stacked_subwindows.shape)\n",
    "    # extract features\n",
    "    extracted_featrues = feature_extractor_model.predict(stacked_subwindows)\n",
    "    \n",
    "    return extracted_featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b602a42e-8b22-4d71-bb4f-c9fd454c5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first work on the train data blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "955b203d-11db-45f4-bfd6-223f9ebb0bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 0101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "914a15bf-0482-4d37-8287-9a8bbea2cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "block_0101 = \"../../Spring_2024/S_lab_TasselNet/Block_1_TN/Block_1_images_and_xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b447139c-e070-43a6-8684-a12d45dd21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_block_0101 = chose_xml_and_jpeg(block_0101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b839ff7a-7e6a-4d05-a5e6-ab297e3d4b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0101_2020_08_26.jpeg',\n",
       " 'Block0101_2020_08_27.jpeg',\n",
       " 'Block0101_2020_08_28.jpeg',\n",
       " 'Block0101_2020_08_31.jpeg',\n",
       " 'Block0101_2020_09_02.jpeg',\n",
       " 'Block0101_2020_09_07.jpeg',\n",
       " 'Block0101_2020_09_16.jpeg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_block_0101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd2d8aac-1793-415d-a100-d943a67a03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 18:31:52.376776: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 5ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.82 s, sys: 275 ms, total: 3.1 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0101_all_features = []\n",
    "for file in images_block_0101:\n",
    "    extracted_features = extract_features(file, block_0101)\n",
    "    blk_0101_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e0cb2d-360e-45fe-8540-2a7a4f8081e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0101_stacked_extracted_features = np.stack(blk_0101_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5e399e-8e6b-4a8e-8bd7-5478242cffce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0101_stacked_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca70a524-7bcf-47a7-8ef5-602c15cf9aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36970586"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the mean of the extracted features match to the ones earlier\n",
    "np.mean(blk_0101_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18f55ebf-68be-4e68-8e8a-14fff9877974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's not save or stack this for now, let's stack all train data in order, and then save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d327717-943a-4591-84d8-7ac0ed8fd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 0102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9d4fb5e-775d-4b29-9d87-6bbfad5d88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_0102 = \"../../Spring_2024/S_lab_TasselNet/Block_2_TN/Block_2_images_and_xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5da19024-20a7-45ea-a98c-75fa1ab53274",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_block_0102 = chose_xml_and_jpeg(block_0102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5b381f-b914-43fd-b7ef-3bd4343ee5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0102_2020_08_26.jpeg',\n",
       " 'Block0102_2020_08_27.jpeg',\n",
       " 'Block0102_2020_08_28.jpeg',\n",
       " 'Block0102_2020_08_31.jpeg',\n",
       " 'Block0102_2020_09_02.jpeg',\n",
       " 'Block0102_2020_09_07.jpeg',\n",
       " 'Block0102_2020_09_16.jpeg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_block_0102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c32f981-c1d4-48e0-913b-8c55c4fef287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.43 s, sys: 155 ms, total: 2.59 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0102_all_features = []\n",
    "for file in images_block_0102:\n",
    "    extracted_features = extract_features(file, block_0102)\n",
    "    blk_0102_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "227e077d-b1db-49c1-8f87-f3c29ab7bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0102_stacked_extracted_features = np.stack(blk_0102_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "188520a0-c26b-48da-8a42-53e1d37f9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0102_stacked_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "806c4871-ffa6-4946-b296-e7589c5a83bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3753665"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the mean of the extracted features match to the ones earlier\n",
    "np.mean(blk_0102_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61710d07-432b-4abf-a424-0a945b00976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 0203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fbb5553-0d30-4b48-91fc-3e158f48eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_0203 = \"../../Spring_2024/S_lab_TasselNet/Block_9_TN/Block_9_images_and_xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db47adc-1bf4-4899-8340-6e3a2b9529e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_block_0203 = chose_xml_and_jpeg(block_0203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8614c17b-a27b-4466-8d69-be8afe159a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0203_2020_08_26.jpeg',\n",
       " 'Block0203_2020_08_27.jpeg',\n",
       " 'Block0203_2020_08_28.jpeg',\n",
       " 'Block0203_2020_08_31.jpeg',\n",
       " 'Block0203_2020_09_02.jpeg',\n",
       " 'Block0203_2020_09_07.jpeg',\n",
       " 'Block0203_2020_09_16.jpeg']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_block_0203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77e3f84e-cefe-4830-b36a-2cd9a0a5983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.4 s, sys: 145 ms, total: 2.54 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0203_all_features = []\n",
    "for file in images_block_0203:\n",
    "    extracted_features = extract_features(file, block_0203)\n",
    "    blk_0203_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "293daac4-3e48-4b6e-9286-3b47243fd5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0203_stacked_extracted_features = np.stack(blk_0203_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9f5d164-e3ac-4279-9175-0e346dede0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0203_stacked_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8ecf583-72e8-480e-ba29-84a5dae6b4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33241686"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the mean of the extracted features match to the ones earlier\n",
    "np.mean(blk_0203_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c135661c-6224-4f1b-81c8-c2686c99b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58e1d09a-c00f-4b48-9dd2-a9f62880c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_0301 = \"../../Spring_2024/S_lab_TasselNet/Block_13_TN/Block_13_images_and_xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42879038-7dec-4b8e-945e-12f0920e1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_block_0301 = chose_xml_and_jpeg(block_0301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eea783f-57b3-47de-9753-de3eb02bc6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0301_2020_08_26.jpeg',\n",
       " 'Block0301_2020_08_27.jpeg',\n",
       " 'Block0301_2020_08_28.jpeg',\n",
       " 'Block0301_2020_08_31.jpeg',\n",
       " 'Block0301_2020_09_02.jpeg',\n",
       " 'Block0301_2020_09_07.jpeg',\n",
       " 'Block0301_2020_09_16.jpeg']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_block_0301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7273a9f8-3880-4a8d-8090-dfeab442973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.44 s, sys: 132 ms, total: 2.57 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0301_all_features = []\n",
    "for file in images_block_0301:\n",
    "    extracted_features = extract_features(file, block_0301)\n",
    "    blk_0301_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "553d1c73-9013-469b-ad5d-a08f822ad1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0301_stacked_extracted_features = np.stack(blk_0301_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dc9168f-6f49-4fdd-9428-dcba03dee00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0301_stacked_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad97af01-5897-44af-97c1-19a625521b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36661348"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the mean of the extracted features match to the ones earlier\n",
    "np.mean(blk_0301_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32360a80-44ef-49a4-9914-068088b42943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can stack all these now and save?\n",
    "\n",
    "all_train_targets_list = [blk_0101_stacked_extracted_features, blk_0102_stacked_extracted_features, blk_0203_stacked_extracted_features, blk_0301_stacked_extracted_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53d46fbb-3ce2-429d-9e1f-34cbf9c22b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all these together?\n",
    "all_train_targets = np.vstack(all_train_targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65d4ddd8-d9e1-4490-bd48-b625787f6daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3640, 7, 32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd8cdffe-8a8e-4b75-8c49-ca24e68126e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(np.mean(all_train_targets[910*0:910*1, :, :] == blk_0101_stacked_extracted_features))\n",
    "print(np.mean(all_train_targets[910*1:910*2, :, :] == blk_0102_stacked_extracted_features))\n",
    "print(np.mean(all_train_targets[910*2:910*3, :, :] == blk_0203_stacked_extracted_features))\n",
    "print(np.mean(all_train_targets[910*3:910*4, :, :] == blk_0301_stacked_extracted_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "647e4e3f-1528-4bf6-8b13-50d5714d4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the stack\n",
    "np.save(\"data/train_out_targets/all_train_targets.npy\", all_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed135016-ffde-49f1-8b2d-47d5a48740cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "np.mean(all_train_targets == np.load(\"data/train_out_targets/all_train_targets.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d334ca3-5937-4289-8514-024122d67759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this also for the validation data, and then stop for the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88bc60a8-1117-4da0-9b72-a9cca4bfa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block 0204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85b5207c-22ca-45b2-9eff-cb43660729f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_0204 = \"../../Spring_2024/S_lab_TasselNet/Block_10_TN/Block_10_images_and_xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47bb38a7-9dbd-4d56-918e-049220609f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_block_0204 = chose_xml_and_jpeg(block_0204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "829db1b5-6c31-44aa-9142-8acf20afdbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Block0204_2020_08_26.jpeg',\n",
       " 'Block0204_2020_08_27.jpeg',\n",
       " 'Block0204_2020_08_28.jpeg',\n",
       " 'Block0204_2020_08_31.jpeg',\n",
       " 'Block0204_2020_09_02.jpeg',\n",
       " 'Block0204_2020_09_07.jpeg',\n",
       " 'Block0204_2020_09_16.jpeg']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_block_0204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88446c59-6966-4642-aae8-c04dab6f5671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "(910, 30, 30, 3)\n",
      "29/29 [==============================] - 0s 2ms/step\n",
      "CPU times: user 2.44 s, sys: 147 ms, total: 2.59 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the extracted input features\n",
    "\n",
    "blk_0204_all_features = []\n",
    "for file in images_block_0204:\n",
    "    extracted_features = extract_features(file, block_0204)\n",
    "    blk_0204_all_features.append(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d7e554a-5b73-4aa9-9e12-39abd7e581d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the extracted features\n",
    "blk_0204_stacked_extracted_features = np.stack(blk_0204_all_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecd27cb5-7e0d-42c8-9d63-ab08754ec008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7, 32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk_0204_stacked_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37c87ae1-6300-45d4-9c61-f83239a7bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36944777"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the mean of the extracted features match to the ones earlier\n",
    "np.mean(blk_0204_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3117fa2-542e-41c1-a292-36834c0adace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "np.save(\"data/valid_out_targets/all_valid_targets.npy\", blk_0204_stacked_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a2d119e-7c71-4641-810b-72b475aaa130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "np.mean(blk_0204_stacked_extracted_features == np.load(\"data/valid_out_targets/all_valid_targets.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
