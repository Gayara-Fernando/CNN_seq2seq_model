{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33f9212-8c56-4c83-933e-f1ce67fb2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:54:29.356627: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-14 10:54:29.395133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-14 10:54:29.395156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-14 10:54:29.396073: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-14 10:54:29.402240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff490c6-cdc2-4b71-9311-b235bbe7d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 10:54:31.188994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# We need the previously trained model? Where is it?\n",
    "CNN_model = tf.keras.models.load_model('../../Spring_2024/Bayes_for_comps/TS_bayes_implementation_for_TN/models/trained_gmp_model_dense_32_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fff3aec-4fc6-44bd-9e1e-20ba6c8adbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_2 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " New_Dense_2 (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      " New_Activation_2 (Activati  (None, 1)                 0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71841 (280.63 KB)\n",
      "Trainable params: 43201 (168.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c596c7-a99b-4b81-9f61-3202cbc0c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only use the part of the model used for featrue extraction\n",
    "\n",
    "feat_ext_input = CNN_model.input\n",
    "\n",
    "feat_ext_output = CNN_model.layers[-4].output\n",
    "\n",
    "feature_extractor_model = tf.keras.models.Model(inputs = feat_ext_input, outputs = feat_ext_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb54240-da3c-4eeb-93f1-023cf59b0a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, None, None, 32)    896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, None, None, 32)    9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, None, None, 32)    0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, None, 32)    0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, None, None, 64)    18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, None, None, 64)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " New_dropout_0 (Dropout)     (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 64)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " New_Dense_0 (Dense)         (None, 64)                4160      \n",
      "                                                                 \n",
      " New_Activation_0 (Activati  (None, 64)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " New_dropout_1 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " New_Dense_1 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " New_Activation_1 (Activati  (None, 32)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d44078-82c5-40a5-bc52-d4249043cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might need to give attention to how the layer weights need to be trained, I think first we freeze everything, and then we unfreeze some, let's look at this in the CNN-LSTM work that was previously done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3d8da8-ce21-4809-8324-c451a9a3cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over here let's just focus on the architecture of the cnn seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd99d035-718f-45ac-acff-252f21d63b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the input would be [None, 13, None, None, 3] - notice that the first dimension is for the time component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb1a806-2594-427e-adba-7a6bef58e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think we wrap this in a time distributed layer? and then pass it throgh a LSTM layer to respect the time dimension. This should give us our encoder part of the model. For now, we will not include teacher forcing, but let's keep in mind this is something we can do to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04393e2c-558a-48c2-ab6a-6bcacff212bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62404083-3644-4ffe-855a-9bb2708a4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = tf.keras.layers.Input(shape = (None, None, None, 3)) # The first None over here represent the time dimension, let's leave it as None instead of 13 for now as it is more generic\n",
    "\n",
    "# pass the model through a time distributed layer\n",
    "td_model = tf.keras.layers.TimeDistributed(feature_extractor_model)\n",
    "\n",
    "td_out = td_model(encoder_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efdd41e-b773-4196-8166-5536359d8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_till_now = tf.keras.models.Model(inputs = encoder_input, outputs = td_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb478ed2-2f1d-4b88-a598-569315294288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, Non   0         \n",
      "                             e, 3)]                              \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, 32)          71808     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_till_now.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2824ad-5f4b-48d3-90cd-1961bef104cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make sure the time dimension is correctly accounted for, let's do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec293ff-2371-4432-9283-52d8897d4491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 13, None, None,   0         \n",
      "                              3)]                                \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 13, 32)            71808     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71808 (280.50 KB)\n",
      "Trainable params: 43168 (168.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_encoder_input = tf.keras.layers.Input(shape = (13, None, None, 3)) \n",
    "test_td_model = tf.keras.layers.TimeDistributed(feature_extractor_model)\n",
    "test_td_out = test_td_model(test_encoder_input)\n",
    "\n",
    "test_model = tf.keras.models.Model(inputs = test_encoder_input, outputs = test_td_out)\n",
    "\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5089f5-b18b-4a3d-b66b-b59a62a9ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now pass an LSTM layer here, without return sequences, as the context vector is probably enough for our decoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c15d235-1065-4573-a246-cdee245084ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "lstm_layer = tf.keras.layers.LSTM(64, activation = \"relu\", return_state = True, return_sequences = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70654eed-6a19-4c63-a40a-3601851e9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, state_h, state_c = lstm_layer(td_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a97e6c5b-38f6-491f-996a-ad80fef21d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.models.Model(inputs = encoder_input, outputs = encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8609837a-d840-4949-9fc7-a3416bb7595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, Non   0         \n",
      "                             e, 3)]                              \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, 32)          71808     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 64),              24832     \n",
      "                              (None, 64),                        \n",
      "                              (None, 64)]                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96640 (377.50 KB)\n",
      "Trainable params: 68000 (265.62 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7830545-a883-407c-9f9d-2115dd0a9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now for the decoder part of the model\n",
    "\n",
    "# We need to repeat the context vector 7 times as the inputs into the decoder\n",
    "\n",
    "decoder_inp = tf.keras.layers.RepeatVector(7)(encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4c9cc7b-f1b3-435d-a936-ca71d61d97ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 7, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42801651-62ce-4afd-a82d-48e2b621803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Have an LSTM here on top of this for the output - and I think here we do need the return sequences to True\n",
    "decoder_lstm = tf.keras.layers.LSTM(64, return_sequences = True, activation = 'relu')\n",
    "\n",
    "decoder_out = decoder_lstm(decoder_inp, initial_state = [state_h, state_c])\n",
    "\n",
    "# And now a dense layer for this - with a time distributed layer - but can do a just Dense too\n",
    "\n",
    "dense_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(32, activation = 'relu'))\n",
    "\n",
    "dense_out = dense_layer(decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd64460a-d99d-4b3f-84ea-7a1614c77564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_till_now = tf.keras.models.Model(inputs = encoder_input, outputs = dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15911199-17c7-4aac-8989-be9b53477b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, None,    0         []                            \n",
      "                             3)]                                                                  \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 32)             71808     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 64),                 24832     ['time_distributed[0][0]']    \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 7, 64)                0         ['lstm[0][0]']                \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 7, 64)                33024     ['repeat_vector[0][0]',       \n",
      "                                                                     'lstm[0][1]',                \n",
      "                                                                     'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, 7, 32)                2080      ['lstm_1[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_till_now.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9423900-5af1-4b58-ac7e-febdbc2fde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all these together and write out the full model for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "febd1305-7cf8-40fe-9687-d86773c68c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "input_time = 13\n",
    "feature_size = 32\n",
    "output_time = 7\n",
    "\n",
    "# Encoder\n",
    "# define encoder input\n",
    "encoder_input = tf.keras.layers.Input(shape = (input_time, None, None, 3)) \n",
    "\n",
    "# pass the feature extractor model through a TD layer\n",
    "td_model = tf.keras.layers.TimeDistributed(feature_extractor_model)\n",
    "\n",
    "td_out = td_model(encoder_input)\n",
    "\n",
    "# add an lstm to process the input sequence\n",
    "lstm_layer = tf.keras.layers.LSTM(64, activation = \"relu\", return_state = True, return_sequences = False)\n",
    "\n",
    "encoder_outputs, state_h, state_c = lstm_layer(td_out)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "# repeat the context vector 7 times\n",
    "decoder_inp = tf.keras.layers.RepeatVector(output_time)(encoder_outputs)\n",
    "\n",
    "# define an LSTM for the output sequence\n",
    "decoder_lstm = tf.keras.layers.LSTM(64, return_sequences = True, activation = 'relu')\n",
    "\n",
    "decoder_out = decoder_lstm(decoder_inp, initial_state = [state_h, state_c])\n",
    "\n",
    "# TD dense layer to generate the output sequnces\n",
    "dense_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(feature_size, activation = 'relu'))\n",
    "\n",
    "dense_out = dense_layer(decoder_out)\n",
    "\n",
    "# define the model\n",
    "CNN_seq2seq_model = tf.keras.models.Model(inputs = encoder_input, outputs = dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65b245ec-ede0-4b71-b238-9b9e5e11dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 13, None, None, 3)   0         []                            \n",
      "                             ]                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDi  (None, 13, 32)               71808     ['input_3[0][0]']             \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 64),                 24832     ['time_distributed_3[0][0]']  \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVec  (None, 7, 64)                0         ['lstm_2[0][0]']              \n",
      " tor)                                                                                             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 7, 64)                33024     ['repeat_vector_1[0][0]',     \n",
      "                                                                     'lstm_2[0][1]',              \n",
      "                                                                     'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDi  (None, 7, 32)                2080      ['lstm_3[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 131744 (514.62 KB)\n",
      "Trainable params: 103104 (402.75 KB)\n",
      "Non-trainable params: 28640 (111.88 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_seq2seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d28a950c-edaf-4f82-b1a2-1a672bd63605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before moving to preprocessing - let's tackle the number of params in each layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nrdstor_tfp_for_TN)",
   "language": "python",
   "name": "nrdstor_tfp_for_tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
